
# BERT-Based Sentiment Analysis Using Movie Reviews

## Summary

This project leverages BERT (Bidirectional Encoder Representations from Transformers) to perform sentiment analysis on movie reviews, aiming to accurately gauge audience emotions and preferences. By utilizing advanced NLP techniques and machine learning models, the analysis classifies reviews as positive or negative, enhancing the understanding of customer sentiment and improving decision-making for movie-related businesses.

### Key Features
- **Data Collection**: Use a dataset of movie reviews from sources like Kaggle.
- **Preprocessing**: Clean and normalize review text, handling punctuation, stopwords, and noise.
- **BERT Model**: Fine-tune a pre-trained BERT model for sentiment classification, achieving high accuracy.
- **Evaluation**: Measure model performance using metrics such as accuracy, precision, recall, and F1-score.
- **Visualization**: Present results through graphs, confusion matrices, and sentiment distribution plots.

### Technologies Used
- Python
- Pandas, NumPy
- Scikit-learn, TensorFlow, PyTorch
- Hugging Face Transformers
- NLTK, SpaCy
- Matplotlib, Seaborn

### How to Use
1. **Clone the Repository**: 
    ```sh
    git clone https://github.com/yourusername/bert-sentiment-analysis-movie-reviews.git
    ```
2. **Install Dependencies**: 
    ```sh
    pip install -r requirements.txt
    ```
3. **Prepare Data**: Ensure the dataset is in the correct format and update paths in the script.
4. **Run the Analysis**: 
    ```sh
    python sentiment_analysis.py
    ```
5. **View Results**: 
    - Results will be saved in the `output` directory.
    - Open `visualization.ipynb` to explore interactive visualizations and performance metrics.

### Contributing
Contributions are welcome! Please fork the repository and submit a pull request with your changes.


## Deploying a BERT Model for Sentiment Analysis

### Steps for Deploying a BERT Model for Sentiment Analysis

1. **Train and Save the Model**:
    - Train your BERT model on the movie reviews dataset.
    - Save the trained model and tokenizer.
    
    ```python
    from transformers import BertTokenizer, BertForSequenceClassification
    
    # Load pre-trained model and tokenizer
    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    
    # Training code here (omitted for brevity)
    
    # Save the model and tokenizer
    model.save_pretrained('path/to/save/model')
    tokenizer.save_pretrained('path/to/save/tokenizer')
    ```

2. **Set Up a Flask API**:
    - Create a Flask app to serve predictions.

    ```python
    from flask import Flask, request, jsonify
    from transformers import BertTokenizer, BertForSequenceClassification
    import torch
    
    app = Flask(__name__)
    
    # Load the model and tokenizer
    model = BertForSequenceClassification.from_pretrained('path/to/save/model')
    tokenizer = BertTokenizer.from_pretrained('path/to/save/tokenizer')
    
    # Define the prediction function
    def predict_sentiment(review_text):
        inputs = tokenizer(review_text, return_tensors='pt', truncation=True, padding=True, max_length=512)
        outputs = model(**inputs)
        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
        confidence, prediction = torch.max(probabilities, dim=1)
        sentiment = 'positive' if prediction.item() == 1 else 'negative'
        return sentiment, confidence.item()
    
    @app.route('/predict', methods=['POST'])
    def predict():
        data = request.json
        review_text = data['review']
        sentiment, confidence = predict_sentiment(review_text)
        return jsonify({'sentiment': sentiment, 'confidence': confidence})
    
    if __name__ == '__main__':
        app.run(debug=True)
    ```

3. **Dockerize the Application**:
    - Create a Dockerfile to containerize the Flask app.

    ```Dockerfile
    # Use an official Python runtime as a parent image
    FROM python:3.8-slim
    
    # Set the working directory
    WORKDIR /app
    
    # Copy the current directory contents into the container at /app
    COPY . /app
    
    # Install any needed packages specified in requirements.txt
    RUN pip install --no-cache-dir -r requirements.txt
    
    # Make port 5000 available to the world outside this container
    EXPOSE 5000
    
    # Define environment variable
    ENV NAME BERT_Sentiment_Analysis
    
    # Run app.py when the container launches
    CMD ["python", "app.py"]
    ```

    - Build and run the Docker container.

    ```sh
    docker build -t bert-sentiment-analysis .
    docker run -p 5000:5000 bert-sentiment-analysis
    ```

4. **Deploy to a Cloud Service**:
    - Deploy the Docker container to a cloud service like AWS, Google Cloud, or Heroku. Each platform has its own deployment steps, but generally, you will push the Docker image to their container registry and then create a service from that image.

### Example Deployment to Heroku
1. **Create a `Procfile`**:

    ```sh
    web: python app.py
    ```

2. **Login to Heroku and Create an App**:

    ```sh
    heroku login
    heroku create bert-sentiment-analysis
    ```

3. **Push the Docker Container to Heroku**:

    ```sh
    heroku container:push web -a bert-sentiment-analysis
    heroku container:release web -a bert-sentiment-analysis
    ```

4. **Open the App**:

    ```sh
    heroku open -a bert-sentiment-analysis
    ```

By following these steps, you can deploy a BERT model for sentiment analysis and serve predictions through a web API. This setup can be customized and scaled according to your needs.
